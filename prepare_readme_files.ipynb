{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation\n",
    "from acquire_msc import get_all_readme_files_and_languages\n",
    "# from acquire_readme_files import temp_get_all_readme_files_and_languages\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = ['microsoft/Terminal', 'jackfrued/Python-100-Days', \n",
    "            'kkuchta/css-only-chat', 'microsoft/PowerToys', 'jolaleye/cssfx', \n",
    "            'MisterBooo/LeetCodeAnimation', 'flutter/flutter_web', \n",
    "            'TheAlgorithms/Python', 'hiroppy/fusuma', 'CyC2018/CS-Notes', \n",
    "            'jaywcjlove/linux-command', 'flutter/flutter', '996icu/996.ICU', \n",
    "            'STVIR/pysot', 'minamarkham/formation', 'azl397985856/leetcode', \n",
    "            'qianguyihao/Web', 'react-native-windows', 'sql-machine-learning/sqlflow', \n",
    "            'sabakkps/backslide', 'dgryski/go-perfbook', 'Snailclimb/JavaGuide', \n",
    "            'microsoft/vscode', 'markphelps/flipt', 'teoga/awesome-product-design']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(article):\n",
    "    '''\n",
    "    take in a string (article) and return it after applying some basic text cleaning to it:\n",
    "        - lowercase everything\n",
    "        - normalize unicode characters\n",
    "        - replace anything that is not a letter, number, whitespace or a single quote\n",
    "    '''\n",
    "    new_article = article.lower()\n",
    "    new_article = re.sub(r'\\s', ' ', new_article)\n",
    "    normalized = unicodedata.normalize('NFKD', new_article)                .encode('ascii', 'ignore')                .decode('utf-8')\n",
    "    without_special_chars = re.sub(r'[^\\w\\s]', ' ', normalized)\n",
    "    word_list = without_special_chars.split()\n",
    "    word_list = ' '.join(word_list)\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(article):\n",
    "    '''tokenize all the words in the string, article'''\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    new_article = tokenizer.tokenize(article, return_str=True)\n",
    "    return new_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stop_words(article):\n",
    "    '''accept some text, apply stemming to all of the words,\n",
    "        and print a list of value counts for all the stemmed words'''\n",
    "    # Create the nltk stemmer object, then use it\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    stems = [ps.stem(word) for word in article.split()]\n",
    "    print(pd.Series(stems).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(article):\n",
    "    '''accept a string and return it after applying stemming to all the words'''\n",
    "    ps = nltk.stem.PorterStemmer()\n",
    "    article_stemmed = ''.join([ps.stem(word) for word in article])\n",
    "    return article_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(article):\n",
    "    '''accept a string and return it after applying lemmatization to each word.'''\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    lemmatized_words = [wnl.lemmatize(word) for word in article]\n",
    "    article_lemmatized = ''.join(lemmatized_words)\n",
    "    return article_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(article, extra_words = None, exclude_words = None):\n",
    "    '''remove all the stopwords, including all the words in extra_words and excluding\n",
    "    all the words in exclude list'''\n",
    "\n",
    "    # get basic stopword list\n",
    "    stopword_list = stopwords.words('english')\n",
    "\n",
    "    # add extra words    \n",
    "    if extra_words != None:\n",
    "        stopword_list = stopword_list + extra_words\n",
    "    # remove excluded words\n",
    "    if exclude_words != None:\n",
    "        stopword_list = [word for word in stopword_list if word not in exclude_words]\n",
    "    \n",
    "    without_stopwords = [word for word in article.split(' ') if word not in stopword_list]\n",
    "    article_without_stopwords = ' '.join(without_stopwords)\n",
    "    return article_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_article(this_dict, extra_words = None, exclude_words = None):\n",
    "    '''\n",
    "    takes in a dictionary representing an article and returns a dictionary that \n",
    "    looks like this:\n",
    "            {\n",
    "             'title': 'the original title',\n",
    "             'original': original,\n",
    "             'stemmed': article_stemmed,\n",
    "             'lemmatized': article_lemmatized,\n",
    "             'clean': article_without_stopwords\n",
    "            }\n",
    "    Note that if the orignal dictionary has a title property, it will remain unchanged \n",
    "    (same goes for the category property).\n",
    "    '''\n",
    "    # put the content section into article and make a copy\n",
    "#     article = articles['content'][article_index]    # needed for \n",
    "    article = this_dict['content']\n",
    "    original = article\n",
    "\n",
    "    '''\n",
    "    apply some basic text cleaning to the string, article:\n",
    "        - lowercase everything\n",
    "        - normalize unicode characters\n",
    "        - replace anything that is not a letter, number, whitespace or a single quote\n",
    "    '''\n",
    "    article = basic_clean(article)\n",
    "\n",
    "    '''tokenize all the words in the string, article'''\n",
    "    article = tokenize(article)\n",
    "\n",
    "    '''applying stemming to all the words in the string, article'''\n",
    "    article_stemmed = stem(article)\n",
    "    \n",
    "    ''''apply lemmatization to each word in the string, article'''\n",
    "    article_lemmatized = lemmatize(article)\n",
    "    \n",
    "    '''remove all the stopwords, including all the words in extra_words and excluding\n",
    "    all the words in exclude list'''\n",
    "    article_without_stopwords = remove_stopwords(article, extra_words, exclude_words)\n",
    "\n",
    "    keys = list(this_dict.keys())\n",
    "    \n",
    "    new_dict = {\n",
    "         'title': this_dict['title'],\n",
    "         'original': original,\n",
    "         'category': [this_dict['category'] if 'category' in keys else 'repo_readme'],\n",
    "         'stemmed': article_stemmed,\n",
    "         'lemmatized': article_lemmatized,\n",
    "         'clean': article_without_stopwords\n",
    "        }\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_article_data(articles, extra_words = None, exclude_words = None):\n",
    "    # takes in the list of articles dictionaries, \n",
    "    # applies the prep_article function to each one, \n",
    "    # and returns the transformed data.\n",
    "    transformed_articles = []\n",
    "\n",
    "    for article_index in range(len(articles)):\n",
    "        transformed_entry = prep_article(articles[article_index], extra_words, exclude_words)\n",
    "        transformed_articles.append(transformed_entry.copy())\n",
    "\n",
    "    return transformed_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prep_news_article(this_dict, extra_words = None, exclude_words = None):\n",
    "#     '''\n",
    "#     takes in a dictionary representing an article and returns a dictionary that \n",
    "#     looks like this:\n",
    "#             {\n",
    "#              'title': 'the original title',\n",
    "#              'original': original,\n",
    "#              'stemmed': article_stemmed,\n",
    "#              'lemmatized': article_lemmatized,\n",
    "#              'clean': article_without_stopwords\n",
    "#             }\n",
    "#     Note that if the orignal dictionary has a title property, it will remain unchanged \n",
    "#     (same goes for the category property).\n",
    "#     '''\n",
    "#     # put the content section into article and make a copy\n",
    "# #     article = articles['content'][article_index]    # needed for \n",
    "#     article = this_dict['content']\n",
    "#     original = article\n",
    "\n",
    "#     '''\n",
    "#     apply some basic text cleaning to the string, article:\n",
    "#         - lowercase everything\n",
    "#         - normalize unicode characters\n",
    "#         - replace anything that is not a letter, number, whitespace or a single quote\n",
    "#     '''\n",
    "#     article = basic_clean(article)\n",
    "\n",
    "#     '''tokenize all the words in the string, article'''\n",
    "#     article = tokenize(article)\n",
    "\n",
    "#     '''applying stemming to all the words in the string, article'''\n",
    "#     article_stemmed = stem(article)\n",
    "    \n",
    "#     ''''apply lemmatization to each word in the string, article'''\n",
    "#     article_lemmatized = lemmatize(article)\n",
    "    \n",
    "#     '''remove all the stopwords, including all the words in extra_words and excluding\n",
    "#     all the words in exclude list'''\n",
    "#     article_without_stopwords = remove_stopwords(article, extra_words, exclude_words)\n",
    "\n",
    "#     keys = list(this_dict.keys())\n",
    "    \n",
    "#     new_dict = {\n",
    "#          'title': this_dict['title'],\n",
    "#          'original': original,\n",
    "#          'category': [this_dict['category'] if 'category' in keys else 'blog'],\n",
    "#          'stemmed': article_stemmed,\n",
    "#          'lemmatized': article_lemmatized,\n",
    "#          'clean': article_without_stopwords\n",
    "#         }\n",
    "#     return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_repo_html(this_dict, extra_words = None, exclude_words = None):\n",
    "    '''\n",
    "    takes in a dictionary representing an article and returns a dictionary that \n",
    "    looks like this:\n",
    "            {\n",
    "             'title': 'the original title',\n",
    "             'original': original,\n",
    "             'clean': article_without_stopwords\n",
    "            }\n",
    "    Note that if the orignal dictionary has a title property, it will remain unchanged \n",
    "    (same goes for the category property).\n",
    "    '''\n",
    "    # put the content section into article and make a copy\n",
    "    article = this_dict['content']\n",
    "    original = article\n",
    "\n",
    "    '''\n",
    "    apply some basic text cleaning to the string, article:\n",
    "        - lowercase everything\n",
    "        - normalize unicode characters\n",
    "        - replace anything that is not a letter, number, whitespace or a single quote\n",
    "    '''\n",
    "    article = basic_clean(article)\n",
    "\n",
    "    '''tokenize all the words in the string, article'''\n",
    "    article = tokenize(article)\n",
    "    \n",
    "    ''''apply lemmatization to each word in the string, article'''\n",
    "    article = lemmatize(article)\n",
    "    \n",
    "    '''remove all the stopwords, including all the words in extra_words and excluding\n",
    "    all the words in exclude list'''\n",
    "    article = remove_stopwords(article, extra_words, exclude_words)\n",
    "\n",
    "    keys = list(this_dict.keys())\n",
    "    \n",
    "    new_dict = {\n",
    "         'title': this_dict['title'],\n",
    "         'category': this_dict['category'] if 'category' in keys else 'repo_readme',        \n",
    "#          'original': original,\n",
    "         'clean': article\n",
    "        }\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_repo_html_data(articles, extra_words = None, exclude_words = None):\n",
    "    # takes in the list of articles dictionaries, \n",
    "    # applies the prep_article function to each one, \n",
    "    # and returns the transformed data.\n",
    "    transformed_articles = []\n",
    "    for article_index in range(len(articles)):\n",
    "        transformed_entry = prep_repo_html(articles[article_index], extra_words, exclude_words)\n",
    "        transformed_articles.append(transformed_entry.copy())\n",
    "        df = pd.DataFrame.from_dict(transformed_data)\n",
    "\n",
    "    return transformed_articles, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "'''create a list of extra words and another of words to exclude from the stoplist'''\n",
    "extra_words = ['codeup']\n",
    "exclude_words = ['']\n",
    "\n",
    "articles = get_all_readme_files_and_languages(url_list)\n",
    "print()\n",
    "transformed_data, df = prepare_repo_html_data(articles, extra_words, exclude_words)\n",
    "# for index in range(len(transformed_data)):\n",
    "#     print ('index:', index)\n",
    "#     for key in transformed_data[index]:\n",
    "#         print('key:', key)\n",
    "#         print(transformed_data[index][key])\n",
    "#         print('*******************')\n",
    "#     print ('$$$$$$$$$$$$$$$$$$$$$$$$$$$$$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>clean</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>repo_readme</td>\n",
       "      <td>welcome repository contains source code window...</td>\n",
       "      <td>microsoft/Terminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>repo_readme</td>\n",
       "      <td>python 100 python python c c python python jav...</td>\n",
       "      <td>jackfrued/Python-100-Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>repo_readme</td>\n",
       "      <td>css chat truly monstrous async web chat using ...</td>\n",
       "      <td>kkuchta/css-only-chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>repo_readme</td>\n",
       "      <td>overview powertoys set utilities power users t...</td>\n",
       "      <td>microsoft/PowerToys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>repo_readme</td>\n",
       "      <td>beautifully simple click copy css effects http...</td>\n",
       "      <td>jolaleye/cssfx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>repo_readme</td>\n",
       "      <td>english version readme click leetcode 3 4 0 1 ...</td>\n",
       "      <td>MisterBooo/LeetCodeAnimation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>repo_readme</td>\n",
       "      <td>welcome code repository flutter web repository...</td>\n",
       "      <td>flutter/flutter_web</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>repo_readme</td>\n",
       "      <td>algorithms python algorithms implemented pytho...</td>\n",
       "      <td>TheAlgorithms/Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>repo_readme</td>\n",
       "      <td>make slides markdown easily write markdown cre...</td>\n",
       "      <td>hiroppy/fusuma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>repo_readme</td>\n",
       "      <td>java offer leetcode linux http socket sql leet...</td>\n",
       "      <td>CyC2018/CS-Notes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>repo_readme</td>\n",
       "      <td>linux command 550 linux linux linux linuxde ne...</td>\n",
       "      <td>jaywcjlove/linux-command</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>repo_readme</td>\n",
       "      <td>flutter google mobile app sdk crafting high qu...</td>\n",
       "      <td>flutter/flutter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>repo_readme</td>\n",
       "      <td>996 icu please note exists official account ap...</td>\n",
       "      <td>996icu/996.ICU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>repo_readme</td>\n",
       "      <td>pysot pysot software system designed sensetime...</td>\n",
       "      <td>STVIR/pysot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>repo_readme</td>\n",
       "      <td>formation formation shell script set macos lap...</td>\n",
       "      <td>minamarkham/formation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>repo_readme</td>\n",
       "      <td>leetcode english leetcode leetcode leetcode an...</td>\n",
       "      <td>azl397985856/leetcode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>repo_readme</td>\n",
       "      <td>https github com qianguyihao web web androidwe...</td>\n",
       "      <td>qianguyihao/Web</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>repo_readme</td>\n",
       "      <td>sqlflow sqlflow sqlflow bridge connects sql en...</td>\n",
       "      <td>sql-machine-learning/sqlflow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>repo_readme</td>\n",
       "      <td>backslide snap backslide cli tool making html ...</td>\n",
       "      <td>sabakkps/backslide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>repo_readme</td>\n",
       "      <td>go perfbook document outlines best practices w...</td>\n",
       "      <td>dgryski/go-perfbook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>repo_readme</td>\n",
       "      <td>java java special sponsors programmer advancem...</td>\n",
       "      <td>Snailclimb/JavaGuide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>repo_readme</td>\n",
       "      <td>visual studio code open source vs code type to...</td>\n",
       "      <td>microsoft/vscode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>repo_readme</td>\n",
       "      <td>feature flag solution runs existing infrastruc...</td>\n",
       "      <td>markphelps/flipt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>repo_readme</td>\n",
       "      <td>awesome product design collection bookmarks re...</td>\n",
       "      <td>teoga/awesome-product-design</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       category                                              clean  \\\n",
       "0   repo_readme  welcome repository contains source code window...   \n",
       "1   repo_readme  python 100 python python c c python python jav...   \n",
       "2   repo_readme  css chat truly monstrous async web chat using ...   \n",
       "3   repo_readme  overview powertoys set utilities power users t...   \n",
       "4   repo_readme  beautifully simple click copy css effects http...   \n",
       "5   repo_readme  english version readme click leetcode 3 4 0 1 ...   \n",
       "6   repo_readme  welcome code repository flutter web repository...   \n",
       "7   repo_readme  algorithms python algorithms implemented pytho...   \n",
       "8   repo_readme  make slides markdown easily write markdown cre...   \n",
       "9   repo_readme  java offer leetcode linux http socket sql leet...   \n",
       "10  repo_readme  linux command 550 linux linux linux linuxde ne...   \n",
       "11  repo_readme  flutter google mobile app sdk crafting high qu...   \n",
       "12  repo_readme  996 icu please note exists official account ap...   \n",
       "13  repo_readme  pysot pysot software system designed sensetime...   \n",
       "14  repo_readme  formation formation shell script set macos lap...   \n",
       "15  repo_readme  leetcode english leetcode leetcode leetcode an...   \n",
       "16  repo_readme  https github com qianguyihao web web androidwe...   \n",
       "17  repo_readme  sqlflow sqlflow sqlflow bridge connects sql en...   \n",
       "18  repo_readme  backslide snap backslide cli tool making html ...   \n",
       "19  repo_readme  go perfbook document outlines best practices w...   \n",
       "20  repo_readme  java java special sponsors programmer advancem...   \n",
       "21  repo_readme  visual studio code open source vs code type to...   \n",
       "22  repo_readme  feature flag solution runs existing infrastruc...   \n",
       "23  repo_readme  awesome product design collection bookmarks re...   \n",
       "\n",
       "                           title  \n",
       "0             microsoft/Terminal  \n",
       "1      jackfrued/Python-100-Days  \n",
       "2          kkuchta/css-only-chat  \n",
       "3            microsoft/PowerToys  \n",
       "4                 jolaleye/cssfx  \n",
       "5   MisterBooo/LeetCodeAnimation  \n",
       "6            flutter/flutter_web  \n",
       "7           TheAlgorithms/Python  \n",
       "8                 hiroppy/fusuma  \n",
       "9               CyC2018/CS-Notes  \n",
       "10      jaywcjlove/linux-command  \n",
       "11               flutter/flutter  \n",
       "12                996icu/996.ICU  \n",
       "13                   STVIR/pysot  \n",
       "14         minamarkham/formation  \n",
       "15         azl397985856/leetcode  \n",
       "16               qianguyihao/Web  \n",
       "17  sql-machine-learning/sqlflow  \n",
       "18            sabakkps/backslide  \n",
       "19           dgryski/go-perfbook  \n",
       "20          Snailclimb/JavaGuide  \n",
       "21              microsoft/vscode  \n",
       "22              markphelps/flipt  \n",
       "23  teoga/awesome-product-design  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''{\n",
    "             'title': 'the original title',\n",
    "             'original': original,\n",
    "             'clean': article_without_stopwords\n",
    "   }\n",
    "'''\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
